{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1MtI6dhdb1n568xnl333ctKqcj1CRXqAt",
      "authorship_tag": "ABX9TyO/djRSGYqNc2Z+7wbFJOHm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sailorcosmos101/Deeplearning_KU_2023/blob/main/PINN_1207.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "sVfTcBR0kadD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0wbnTe0jxj1",
        "outputId": "7b7fdd7f-7350-495d-9a4f-70379c3cb0db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-05 21:43:42.753183: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-05 21:43:42.753250: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-05 21:43:42.753287: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-05 21:43:46.711422: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/tf_upgrade_v2\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/tools/compatibility/tf_upgrade_v2_main.py\", line 156, in main\n",
            "    files_processed, report_text, errors = process_file(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/tools/compatibility/tf_upgrade_v2_main.py\", line 40, in process_file\n",
            "    upgrader.process_file(in_filename, out_filename)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/tools/compatibility/ast_edits.py\", line 909, in process_file\n",
            "    with open(in_filename, \"r\") as in_file, \\\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'SteadyFlowCylinder_mixed.py'\n"
          ]
        }
      ],
      "source": [
        "!tf_upgrade_v2 --infile SteadyFlowCylinder_mixed.py --outfile spgraded.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pyDOE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvUOLuIYlJTB",
        "outputId": "1d1f5857-545d-499e-d2ac-cbd4cc5d3248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyDOE\n",
            "  Downloading pyDOE-0.3.8.zip (22 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyDOE) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pyDOE) (1.11.4)\n",
            "Building wheels for collected packages: pyDOE\n",
            "  Building wheel for pyDOE (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyDOE: filename=pyDOE-0.3.8-py3-none-any.whl size=18168 sha256=c88fc63af179cdce19e17e712b11b6a4e21e84bfc0d87addd6a37162ea8d720e\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/b6/d7/c6b64746dba6433c593e471e0ac3acf4f36040456d1d160d17\n",
            "Successfully built pyDOE\n",
            "Installing collected packages: pyDOE\n",
            "Successfully installed pyDOE-0.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from pyDOE import lhs\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import scipy.io\n",
        "import random\n",
        "\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # CPU:-1; GPU0: 1; GPU1: 0;\n",
        "\n",
        "random.seed(1111)\n",
        "np.random.seed(1111)\n",
        "tf.compat.v1.set_random_seed(1111)"
      ],
      "metadata": {
        "id": "IMTpYLQclFMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PINN_laminar_flow:\n",
        "    # Initialize the class\n",
        "    def __init__(self, Collo, INLET, OUTLET, WALL, UV_layers, LB, UB, ExistModel=0, uvDir=''):\n",
        "\n",
        "        # count for  callback function\n",
        "        self.count=0\n",
        "        # Mat. properties\n",
        "        self.rho=1.0\n",
        "        self.mu=0.02\n",
        "        # Boundary\n",
        "        self.LB=LB\n",
        "        self.UB=UB\n",
        "        # Define layers\n",
        "        self.UV_layers = UV_layers\n",
        "        self.loss_rec = []\n",
        "\n",
        "        # Collocation point\n",
        "        self.x_c = Collo[:, 0:1]\n",
        "        self.y_c = Collo[:, 1:2]\n",
        "        self.x_INLET = INLET[:, 0:1]\n",
        "        self.y_INLET = INLET[:, 1:2]\n",
        "        self.u_INLET = INLET[:, 2:3]\n",
        "        self.v_INLET = INLET[:, 3:4]\n",
        "        self.x_OUTLET = OUTLET[:, 0:1]\n",
        "        self.y_OUTLET = OUTLET[:, 1:2]\n",
        "        self.x_WALL = WALL[:, 0:1]\n",
        "        self.y_WALL = WALL[:, 1:2]\n",
        "\n",
        "        # Initialize neural networks\n",
        "        self.uv_weights, self.uv_biases = self.initialize_NN(self.UV_layers)\n",
        "\n",
        "        # placeholders\n",
        "        self.learning_rate = tf.compat.v1.placeholder(tf.float32, shape=[])\n",
        "        self.x_tf = tf.compat.v1.placeholder(tf.float32, shape=[None, self.x_c.shape[1]])\n",
        "        self.y_tf = tf.compat.v1.placeholder(tf.float32, shape=[None, self.y_c.shape[1]])\n",
        "        self.x_WALL_tf = tf.compat.v1.placeholder(tf.float32, shape=[None, self.x_WALL.shape[1]])\n",
        "        self.y_WALL_tf = tf.compat.v1.placeholder(tf.float32, shape=[None, self.y_WALL.shape[1]])\n",
        "        self.x_OUTLET_tf = tf.compat.v1.placeholder(tf.float32, shape=[None, self.x_OUTLET.shape[1]])\n",
        "        self.y_OUTLET_tf = tf.compat.v1.placeholder(tf.float32, shape=[None, self.y_OUTLET.shape[1]])\n",
        "        self.x_INLET_tf = tf.compat.v1.placeholder(tf.float32, shape=[None, self.x_INLET.shape[1]])\n",
        "        self.y_INLET_tf = tf.compat.v1.placeholder(tf.float32, shape=[None, self.y_INLET.shape[1]])\n",
        "        self.u_INLET_tf = tf.compat.v1.placeholder(tf.float32, shape=[None, self.u_INLET.shape[1]])\n",
        "        self.v_INLET_tf = tf.compat.v1.placeholder(tf.float32, shape=[None, self.v_INLET.shape[1]])\n",
        "        self.x_c_tf = tf.compat.v1.placeholder(tf.float32, shape=[None, self.x_c.shape[1]])\n",
        "        self.y_c_tf = tf.compat.v1.placeholder(tf.float32, shape=[None, self.y_c.shape[1]])\n",
        "\n",
        "        # graphs\n",
        "        self.u_pred, self.v_pred, self.p_pred, _, _, _, self.c_pred = self.net_uv(self.x_tf, self.y_tf)\n",
        "        self.f_pred_u, self.f_pred_v, self.f_pred_s11, self.f_pred_s22, self.f_pred_s12, \\\n",
        "            self.f_pred_p, self.f_pred_c = self.net_f(self.x_c_tf, self.y_c_tf)\n",
        "        self.u_WALL_pred, self.v_WALL_pred, _, _, _, _, _ = self.net_uv(self.x_WALL_tf, self.y_WALL_tf)\n",
        "        self.u_INLET_pred, self.v_INLET_pred, _, _, _, _, _ = self.net_uv(self.x_INLET_tf, self.y_INLET_tf)\n",
        "        _, _, self.p_OUTLET_pred, _, _, _, _ = self.net_uv(self.x_OUTLET_tf, self.y_OUTLET_tf)\n",
        "\n",
        "        self.loss_f = tf.reduce_mean(tf.square(self.f_pred_u)) + tf.reduce_mean(tf.square(self.f_pred_v)) + (tf.square(self.f_pred_s11))\\\n",
        "                      + tf.reduce_mean(tf.square(self.f_pred_s22)) + tf.reduce_mean(tf.square(self.f_pred_s12)) + tf.reduce_mean(tf.square(self.f_pred_p))\n",
        "        self.loss_WALL = tf.reduce_mean(tf.square(self.u_WALL_pred)) + tf.reduce_mean(tf.square(self.v_WALL_pred))\n",
        "        self.loss_INLET = tf.reduce_mean(tf.square(self.u_INLET_pred-self.u_INLET_tf)) + tf.reduce_mean(tf.square(self.v_INLET_pred-self.v_INLET_tf))\n",
        "        self.loss_OUTLET = tf.reduce_mean(tf.square(self.p_OUTLET_pred))\n",
        "        self.loss_conc = tf.reduce_mean(tf.square(self.f_pred_c))\n",
        "        self.loss = self.loss_f + 1*(self.loss_WALL + self.loss_INLET + self.loss_OUTLET )+ 1*self.los_conc\n",
        "\n",
        "        # Optimizer for solution\n",
        "        self.optimizer_Adam = tf.compat.v1.train.AdamOptimizer(learning_rate = self.learning_rate)\n",
        "        self.train_op_Adam = self.optimizer_Adam.minimize(self.loss, var_list=self.uv_weights + self.uv_biases)\n",
        "\n",
        "        # tf session\n",
        "        self.sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(allow_soft_placement=True, log_device_placement=True))\n",
        "        init = tf.compat.v1.global_variables_initializer()\n",
        "        self.sess.run(init)\n",
        "\n",
        "    def initialize_NN(self, layers):\n",
        "        weights = []\n",
        "        biases = []\n",
        "        num_layers = len(layers)\n",
        "        for l in range(0, num_layers - 1):\n",
        "            W = self.xavier_init(size=[layers[l], layers[l + 1]])\n",
        "            b = tf.Variable(tf.zeros([1, layers[l + 1]], dtype=tf.float32), dtype=tf.float32)\n",
        "            weights.append(W)\n",
        "            biases.append(b)\n",
        "        return weights, biases\n",
        "\n",
        "    def xavier_init(self, size):\n",
        "        in_dim = size[0]\n",
        "        out_dim = size[1]\n",
        "        xavier_stddev = np.sqrt(2 / (in_dim + out_dim))\n",
        "        return tf.Variable(tf.random.truncated_normal([in_dim, out_dim], stddev=xavier_stddev, dtype=tf.float32), dtype=tf.float32)\n",
        "\n",
        "    def save_NN(self, fileDir):\n",
        "        uv_weights = self.sess.run(self.uv_weights)\n",
        "        uv_biases = self.sess.run(self.uv_biases)\n",
        "        with open(fileDir, 'wb') as f:\n",
        "            pickle.dump([uv_weights, uv_biases], f)\n",
        "            print(\"Save uv NN parameters successfully...\")\n",
        "\n",
        "    def neural_net(self, X, weights, biases):\n",
        "        num_layers = len(weights) + 1\n",
        "        H = X\n",
        "        for l in range(0, num_layers - 2):\n",
        "            W = weights[l]\n",
        "            b = biases[l]\n",
        "            H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
        "        W = weights[-1]\n",
        "        b = biases[-1]\n",
        "        Y = tf.add(tf.matmul(H, W), b)\n",
        "        return Y\n",
        "\n",
        "    def net_uv(self, x, y):\n",
        "        psips = self.neural_net(tf.concat([x, y], 1), self.uv_weights, self.uv_biases)\n",
        "        psi = psips[:,0:1]\n",
        "        p = psips[:,1:2]\n",
        "        s11 = psips[:, 2:3]\n",
        "        s22 = psips[:, 3:4]\n",
        "        s12 = psips[:, 4:5]\n",
        "        u = tf.gradients(psi, y)[0]\n",
        "        v = -tf.gradients(psi, x)[0]\n",
        "        c = psips[:,5:6]\n",
        "        return u, v, p, s11, s22, s12, c\n",
        "\n",
        "    def net_f(self, x, y):\n",
        "        rho=self.rho\n",
        "        mu=self.mu\n",
        "        u, v, p, s11, s22, s12, c = self.net_uv(x, y)\n",
        "        s11_1 = tf.gradients(s11, x)[0]\n",
        "        s12_2 = tf.gradients(s12, y)[0]\n",
        "        s22_2 = tf.gradients(s22, y)[0]\n",
        "        s12_1 = tf.gradients(s12, x)[0]\n",
        "        # Plane stress problem\n",
        "        u_x = tf.gradients(u, x)[0]\n",
        "        u_y = tf.gradients(u, y)[0]\n",
        "        v_x = tf.gradients(v, x)[0]\n",
        "        v_y = tf.gradients(v, y)[0]\n",
        "\n",
        "        # f_u:=Sxx_x+Sxy_y\n",
        "        f_u = rho*(u*u_x + v*u_y) - s11_1 - s12_2\n",
        "        f_v = rho*(u*v_x + v*v_y) - s12_1 - s22_2\n",
        "\n",
        "        # f_mass = u_x+v_y\n",
        "        f_s11 = -p + 2*mu*u_x - s11\n",
        "        f_s22 = -p + 2*mu*v_y - s22\n",
        "        f_s12 = mu*(u_y+v_x) - s12\n",
        "        f_p = p + (s11+s22)/2\n",
        "\n",
        "        # conc = diffusion + advection\n",
        "        D_x = 0.003\n",
        "        D_y = 0.001\n",
        "        c_x = tf.gradients(c, x)[0]\n",
        "        c_y = tf.gradients(c, y)[0]\n",
        "        c_x2 = tf.gradients(c_x, x)[0]\n",
        "        c_y2 = tf.gradients(c_y, y)[0]\n",
        "        f_c = D_x * c_x2 + D_y * c_y2 - (v_x * c_x + v_y * c_y)\n",
        "\n",
        "        return f_u, f_v, f_s11, f_s22, f_s12, f_p, f_c\n",
        "\n",
        "\n",
        "    def callback(self, loss):\n",
        "        self.count = self.count+1\n",
        "        self.loss_rec.append(loss)\n",
        "        print('{} th iterations, Loss: {}'.format(self.count, loss))\n",
        "\n",
        "    def train(self, iter, learning_rate):\n",
        "        tf_dict = {self.x_c_tf: self.x_c, self.y_c_tf: self.y_c, self.x_WALL_tf: self.x_WALL, self.y_WALL_tf: self.y_WALL, self.x_INLET_tf: self.x_INLET,\n",
        "                   self.y_INLET_tf: self.y_INLET, self.u_INLET_tf: self.u_INLET, self.v_INLET_tf: self.v_INLET, self.x_OUTLET_tf: self.x_OUTLET,\n",
        "                   self.y_OUTLET_tf: self.y_OUTLET, self.learning_rate: learning_rate}\n",
        "\n",
        "        loss_WALL = []\n",
        "        loss_f = []\n",
        "        loss_INLET = []\n",
        "        loss_OUTLET = []\n",
        "        loss_conc = []\n",
        "\n",
        "        for it in range(iter):\n",
        "            self.sess.run(self.train_op_Adam, tf_dict)\n",
        "            if it % 10 == 0:\n",
        "                loss_value = self.sess.run(self.loss, tf_dict)\n",
        "                print('Iteration: %d, Loss: %.3e' % (it, loss_value))\n",
        "            loss_WALL.append(self.sess.run(self.loss_WALL, tf_dict))\n",
        "            loss_f.append(self.sess.run(self.loss_f, tf_dict))\n",
        "            self.loss_rec.append(self.sess.run(self.loss, tf_dict))\n",
        "            loss_INLET.append(self.sess.run(self.loss_INLET, tf_dict))\n",
        "            loss_OUTLET.append(self.sess.run(self.loss_OUTLET, tf_dict))\n",
        "            loss_conc.append(self.sess.run(self.loss_conc,tf_dict))\n",
        "        return loss_WALL, loss_INLET, loss_OUTLET, loss_f, loss_conc, self.loss\n",
        "\n",
        "    def train_bfgs(self):\n",
        "        tf_dict = {self.x_c_tf: self.x_c, self.y_c_tf: self.y_c, self.x_WALL_tf: self.x_WALL, self.y_WALL_tf: self.y_WALL, self.x_INLET_tf: self.x_INLET,\n",
        "                   self.y_INLET_tf: self.y_INLET, self.u_INLET_tf: self.u_INLET, self.v_INLET_tf: self.v_INLET, self.x_OUTLET_tf: self.x_OUTLET, self.y_OUTLET_tf: self.y_OUTLET}\n",
        "        self.optimizer.minimize(self.sess, feed_dict=tf_dict, fetches=[self.loss],loss_callback=self.callback)\n",
        "\n",
        "    def predict(self, x_star, y_star):\n",
        "        u_star = self.sess.run(self.u_pred, {self.x_tf: x_star, self.y_tf: y_star})\n",
        "        v_star = self.sess.run(self.v_pred, {self.x_tf: x_star, self.y_tf: y_star})\n",
        "        p_star = self.sess.run(self.p_pred, {self.x_tf: x_star, self.y_tf: y_star})\n",
        "        c_star = self.sess.run(self.c_pred, {self.x_tf: x_star, self.y_tf: y_star})\n",
        "        return u_star, v_star, p_star, c_star\n",
        "\n",
        "    def getloss(self):\n",
        "        tf_dict = {self.x_c_tf: self.x_c, self.y_c_tf: self.y_c, self.x_WALL_tf: self.x_WALL, self.y_WALL_tf: self.y_WALL, self.x_INLET_tf: self.x_INLET,\n",
        "                   self.y_INLET_tf: self.y_INLET, self.u_INLET_tf: self.u_INLET, self.v_INLET_tf: self.v_INLET, self.x_OUTLET_tf: self.x_OUTLET, self.y_OUTLET_tf: self.y_OUTLET}\n",
        "        loss_f = self.sess.run(self.loss_f, tf_dict)\n",
        "        loss_WALL = self.sess.run(self.loss_WALL, tf_dict)\n",
        "        loss_INLET = self.sess.run(self.loss_INLET, tf_dict)\n",
        "        loss = self.sess.run(self.loss, tf_dict)\n",
        "        loss_OUTLET = self.sess.run(self.loss_OUTLET, tf_dict)\n",
        "        loss_conc = self.sess.run(self.loss_conc, tf_dict)\n",
        "        return loss_WALL, loss_INLET, loss_OUTLET, loss_f, loss"
      ],
      "metadata": {
        "id": "gfNWyyDclOrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DelCylPT(XY_c, xc=0.0, yc=0.0, r=0.1):\n",
        "    dst = np.array([((xy[0] - xc) ** 2 + (xy[1] - yc) ** 2) ** 0.5 for xy in XY_c])\n",
        "    return XY_c[dst>r,:]"
      ],
      "metadata": {
        "id": "LD2lHUl-lTUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def postProcess(xmin, xmax, ymin, ymax, field, s=2, alpha=0.5, marker='o'):\n",
        "    [x, y, u, v, p, c] = field\n",
        "    fig, ax = plt.subplots(nrows=4, ncols=2, figsize=(14,10))\n",
        "    fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
        "\n",
        "    cf = ax[0, 0].scatter(x, y, c=u, alpha=alpha-0.1, edgecolors='none', cmap='rainbow', marker=marker, s=int(s))\n",
        "    ax[0, 0].axis('square')\n",
        "    for key, spine in ax[0, 0].spines.items():\n",
        "        if key in ['right','top','left','bottom']:\n",
        "            spine.set_visible(False)\n",
        "    ax[0, 0].set_xticks([])\n",
        "    ax[0, 0].set_yticks([])\n",
        "    ax[0, 0].set_xlim([xmin, xmax])\n",
        "    ax[0, 0].set_ylim([ymin, ymax])\n",
        "    ax[0, 0].set_title(r'$u$ (m/s)')\n",
        "    fig.colorbar(cf, ax=ax[0, 0], fraction=0.046, pad=0.04)\n",
        "\n",
        "    cf = ax[1, 0].scatter(x, y, c=v, alpha=alpha-0.1, edgecolors='none', cmap='rainbow', marker=marker, s=int(s))\n",
        "    ax[1, 0].axis('square')\n",
        "    for key, spine in ax[1, 0].spines.items():\n",
        "        if key in ['right','top','left','bottom']:\n",
        "            spine.set_visible(False)\n",
        "    ax[1, 0].set_xticks([])\n",
        "    ax[1, 0].set_yticks([])\n",
        "    ax[1, 0].set_xlim([xmin, xmax])\n",
        "    ax[1, 0].set_ylim([ymin, ymax])\n",
        "    ax[1, 0].set_title(r'$v$ (m/s)')\n",
        "    fig.colorbar(cf, ax=ax[1, 0], fraction=0.046, pad=0.04)\n",
        "\n",
        "    cf = ax[2, 0].scatter(x, y, c=p, alpha=alpha, edgecolors='none', cmap='rainbow', marker=marker, s=int(s), vmin=-0.25, vmax=4.0)\n",
        "    ax[2, 0].axis('square')\n",
        "    for key, spine in ax[2, 0].spines.items():\n",
        "        if key in ['right','top','left','bottom']:\n",
        "            spine.set_visible(False)\n",
        "    ax[2, 0].set_xticks([])\n",
        "    ax[2, 0].set_yticks([])\n",
        "    ax[2, 0].set_xlim([xmin, xmax])\n",
        "    ax[2, 0].set_ylim([ymin, ymax])\n",
        "    ax[2, 0].set_title('Pressure (Pa)')\n",
        "    fig.colorbar(cf, ax=ax[2, 0], fraction=0.046, pad=0.04)\n",
        "\n",
        "    cf = ax[3,0].scatter(x, y, c=c, alpha=alpha, edgecolors='none', cmap='rainbow', marker=marker, s=int(s), vmin=-0.25, vmax=4.0)\n",
        "    ax[3, 0].axis('square')\n",
        "    for key, spine in ax[3, 0].spines.items():\n",
        "        if key in ['right','top','left','bottom']:\n",
        "            spine.set_visible(False)\n",
        "    ax[3, 0].set_xticks([])\n",
        "    ax[3, 0].set_yticks([])\n",
        "    ax[3, 0].set_xlim([xmin, xmax])\n",
        "    ax[3, 0].set_ylim([ymin, ymax])\n",
        "    ax[3, 0].set_title('Concentration')\n",
        "    fig.colorbar(cf, ax=ax[3, 0], fraction=0.046, pad=0.04)\n",
        "\n",
        "\n",
        "    plt.savefig('./uvp.png', dpi=300)\n",
        "    plt.close('all')"
      ],
      "metadata": {
        "id": "gG8a-LV_lVyw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "399cc9b5-7f93-4064-e812-74101643944c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n    # Plot FLUENT result\\n    cf = ax[0, 1].scatter(x_FLUENT, y_FLUENT, c=u_FLUENT, alpha=alpha, edgecolors='none', cmap='rainbow', marker=marker, s=s)\\n    ax[0, 1].axis('square')\\n    for key, spine in ax[0, 1].spines.items():\\n        if key in ['right','top','left','bottom']:\\n            spine.set_visible(False)\\n    ax[0, 1].set_xticks([])\\n    ax[0, 1].set_yticks([])\\n    ax[0, 1].set_xlim([xmin, xmax])\\n    ax[0, 1].set_ylim([ymin, ymax])\\n    ax[0, 1].set_title(r'$u$ (m/s)')\\n    fig.colorbar(cf, ax=ax[0, 1], fraction=0.046, pad=0.04)\\n\\n    cf = ax[1, 1].scatter(x_FLUENT, y_FLUENT, c=v_FLUENT, alpha=alpha, edgecolors='none', cmap='rainbow', marker=marker, s=s)\\n    ax[1, 1].axis('square')\\n    for key, spine in ax[1, 1].spines.items():\\n        if key in ['right','top','left','bottom']:\\n            spine.set_visible(False)\\n    ax[1, 1].set_xticks([])\\n    ax[1, 1].set_yticks([])\\n    ax[1, 1].set_xlim([xmin, xmax])\\n    ax[1, 1].set_ylim([ymin, ymax])\\n    ax[1, 1].set_title(r'$v$ (m/s)')\\n    fig.colorbar(cf, ax=ax[1, 1], fraction=0.046, pad=0.04)\\n\\n    cf = ax[2, 1].scatter(x_FLUENT, y_FLUENT, c=p_FLUENT, alpha=alpha, edgecolors='none', cmap='rainbow', marker=marker, s=s, vmin=-0.25, vmax=4.0)\\n    ax[2, 1].axis('square')\\n    for key, spine in ax[2, 1].spines.items():\\n        if key in ['right','top','left','bottom']:\\n            spine.set_visible(False)\\n    ax[2, 1].set_xticks([])\\n    ax[2, 1].set_yticks([])\\n    ax[2, 1].set_xlim([xmin, xmax])\\n    ax[2, 1].set_ylim([ymin, ymax])\\n    ax[2, 1].set_title('Pressure (Pa)')\\n    fig.colorbar(cf, ax=ax[2, 1], fraction=0.046, pad=0.04)\\n\\n    cf = ax[3, 1].scatter(x_MIXED, y_MIXED, c=p_MIXED, alpha=alpha, edgecolors='none', cmap='rainbow', marker=marker, s=int(s), vmin=-0.25, vmax=4.0)\\n    ax[3, 1].axis('square')\\n    for key, spine in ax[3, 1].spines.items():\\n        if key in ['right','top','left','bottom']:\\n            spine.set_visible(False)\\n    ax[3, 1].set_xticks([])\\n    ax[3, 1].set_yticks([])\\n    ax[3, 1].set_xlim([xmin, xmax])\\n    ax[3, 1].set_ylim([ymin, ymax])\\n    ax[3, 1].set_title('Concentration')\\n    fig.colorbar(cf, ax=ax[3, 1], fraction=0.046, pad=0.04)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def multiple_formatter(denominator=2, number=np.pi, latex='\\pi'):\n",
        "    def gcd(a, b):\n",
        "        while b:\n",
        "            a, b = b, a%b\n",
        "        return a\n",
        "    def _multiple_formatter(x, pos):\n",
        "        den = denominator\n",
        "        num = np.int(np.rint(den*x/number))\n",
        "        com = gcd(num,den)\n",
        "        (num,den) = (int(num/com),int(den/com))\n",
        "        if den==1:\n",
        "            if num==0:\n",
        "                return r'$0$'\n",
        "            if num==1:\n",
        "                return r'$%s$'%latex\n",
        "            elif num==-1:\n",
        "                return r'$-%s$'%latex\n",
        "            else:\n",
        "                return r'$%s%s$'%(num,latex)\n",
        "        else:\n",
        "            if num==1:\n",
        "                return r'$\\frac{%s}{%s}$'%(latex,den)\n",
        "            elif num==-1:\n",
        "                return r'$\\frac{-%s}{%s}$'%(latex,den)\n",
        "            else:\n",
        "                return r'$\\frac{%s%s}{%s}$'%(num,latex,den)\n",
        "    return _multiple_formatter"
      ],
      "metadata": {
        "id": "0Wiyy3N3oqsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Multiple:\n",
        "    def __init__(self, denominator=2, number=np.pi, latex='\\pi'):\n",
        "        self.denominator = denominator\n",
        "        self.number = number\n",
        "        self.latex = latex\n",
        "\n",
        "    def locator(self):\n",
        "        return plt.MultipleLocator(self.number / self.denominator)\n",
        "\n",
        "    def formatter(self):\n",
        "        return plt.FuncFormatter(multiple_formatter(self.denominator, self.number, self.latex))"
      ],
      "metadata": {
        "id": "eojf4LVtlamK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Domain bounds\n",
        "    LB = np.array([0, 0])\n",
        "    UB = np.array([1.2, 0.40])\n",
        "    # Network configuration\n",
        "    UV_layers = [2] + 8*[50] + [5]\n",
        "\n",
        "    # WALL = [x, y], u=v=0\n",
        "    wall_up = [0.0, 0.40] + [1.2, 0.0] * lhs(2, 441)\n",
        "    wall_lw = [0.0, 0.00] + [1.2, 0.0] * lhs(2, 441)\n",
        "    # INLET = [x, y, u, v]\n",
        "    U_max = 1.0\n",
        "    INLET = [0.0, 0.0] + [0.0, 0.40] * lhs(2, 201)\n",
        "    y_INLET = INLET[:,1:2]\n",
        "    u_INLET = 4*U_max*y_INLET*(0.40-y_INLET)/(0.40**2)\n",
        "    v_INLET = 0*y_INLET\n",
        "    INLET = np.concatenate((INLET, u_INLET, v_INLET), 1)\n",
        "    # INLET = [x, y], p=0\n",
        "    OUTLET = [1.2, 0.0] + [0.0, 0.40] * lhs(2, 201)\n",
        "    # Cylinder surface\n",
        "    r = 0.05\n",
        "    theta = [0.0] + [2*np.pi] * lhs(1, 251)\n",
        "    x_CYLD = np.multiply(r, np.cos(theta))+0.2\n",
        "    y_CYLD = np.multiply(r, np.sin(theta))+0.2\n",
        "    CYLD = np.concatenate((x_CYLD, y_CYLD), 1)\n",
        "    WALL = np.concatenate((CYLD, wall_up, wall_lw), 0)\n",
        "\n",
        "    # Collocation point for equation residual\n",
        "    XY_c = lb + (ub - lb) * lhs(2, 40000)\n",
        "    XY_c_refine = [0.1, 0.1] + [0.2, 0.2] * lhs(2, 10000)\n",
        "    XY_c = np.concatenate((XY_c, XY_c_refine), 0)\n",
        "    XY_c = DelCylPT(XY_c, xc=0.2, yc=0.2, r=0.05)\n",
        "    XY_c = np.concatenate((XY_c, WALL, CYLD, OUTLET, INLET[:,0:2]), 0)\n",
        "    print(XY_c.shape)\n",
        "\n",
        "    # Visualize the collocation points\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.set_aspect('equal')\n",
        "    plt.scatter(XY_c[:,0:1], XY_c[:,1:2], marker='o', alpha=0.1 ,color='blue')\n",
        "    plt.scatter(WALL[:,0:1], WALL[:,1:2], marker='o', alpha=0.2 , color='green')\n",
        "    plt.scatter(OUTLET[:, 0:1], OUTLET[:, 1:2], marker='o', alpha=0.2, color='orange')\n",
        "    plt.scatter(INLET[:, 0:1], INLET[:, 1:2], marker='o', alpha=0.2, color='red')\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "MDJuJJ07lcWq",
        "outputId": "28105bea-b3c3-44ae-d80f-9421a95d3dc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(49154, 2)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    with tf.device('/device:GPU:0'):\n",
        "        config = tf.compat.v1.ConfigProto()\n",
        "        config.gpu_options.allow_growth = True\n",
        "        session = tf.compat.v1.Session(config=config)\n",
        "        # Train from scratch\n",
        "        model = PINN_laminar_flow(XY_c, INLET, OUTLET, WALL, UV_layers, LB, UB)\n",
        "        start_time = time.time()\n",
        "        loss_WALL, loss_INLET, loss_OUTLET, loss_f,loss_conc, loss = model.train(iter=10000, learning_rate=5e-4)\n",
        "        # model.train_bfgs()\n",
        "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "        # Save neural network\n",
        "        model.save_NN('drive/MyDrive/uvNN.pickle')\n",
        "        # Save loss history\n",
        "        with open('loss_history.pickle', 'wb') as f:\n",
        "            pickle.dump(model.loss_rec, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqiT5U-UpBxz",
        "outputId": "ff69ac23-5688-4ce2-a19f-dccea7daf5f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "\n",
            "It: 0, Loss: 5.456e-01\n",
            "It: 10, Loss: 3.324e-01\n",
            "It: 20, Loss: 3.062e-01\n",
            "It: 30, Loss: 2.892e-01\n",
            "It: 40, Loss: 2.734e-01\n",
            "It: 50, Loss: 2.527e-01\n",
            "It: 60, Loss: 2.327e-01\n",
            "It: 70, Loss: 2.156e-01\n",
            "It: 80, Loss: 2.017e-01\n",
            "It: 90, Loss: 1.951e-01\n",
            "It: 100, Loss: 1.919e-01\n",
            "It: 110, Loss: 1.900e-01\n",
            "It: 120, Loss: 1.888e-01\n",
            "It: 130, Loss: 1.878e-01\n",
            "It: 140, Loss: 1.867e-01\n",
            "It: 150, Loss: 1.855e-01\n",
            "It: 160, Loss: 1.837e-01\n",
            "It: 170, Loss: 1.809e-01\n",
            "It: 180, Loss: 1.752e-01\n",
            "It: 190, Loss: 1.623e-01\n",
            "It: 200, Loss: 1.258e-01\n",
            "It: 210, Loss: 1.201e-01\n",
            "It: 220, Loss: 1.125e-01\n",
            "It: 230, Loss: 1.093e-01\n",
            "It: 240, Loss: 1.081e-01\n",
            "It: 250, Loss: 1.072e-01\n",
            "It: 260, Loss: 1.065e-01\n",
            "It: 270, Loss: 1.060e-01\n",
            "It: 280, Loss: 1.056e-01\n",
            "It: 290, Loss: 1.052e-01\n",
            "It: 300, Loss: 1.049e-01\n",
            "It: 310, Loss: 1.046e-01\n",
            "It: 320, Loss: 1.043e-01\n",
            "It: 330, Loss: 1.042e-01\n",
            "It: 340, Loss: 1.048e-01\n",
            "It: 350, Loss: 1.042e-01\n",
            "It: 360, Loss: 1.036e-01\n",
            "It: 370, Loss: 1.033e-01\n",
            "It: 380, Loss: 1.031e-01\n",
            "It: 390, Loss: 1.028e-01\n",
            "It: 400, Loss: 1.026e-01\n",
            "It: 410, Loss: 1.025e-01\n",
            "It: 420, Loss: 1.023e-01\n",
            "It: 430, Loss: 1.021e-01\n",
            "It: 440, Loss: 1.019e-01\n",
            "It: 450, Loss: 1.017e-01\n",
            "It: 460, Loss: 1.015e-01\n",
            "It: 470, Loss: 1.023e-01\n",
            "It: 480, Loss: 1.025e-01\n",
            "It: 490, Loss: 1.014e-01\n",
            "It: 500, Loss: 1.009e-01\n",
            "It: 510, Loss: 1.005e-01\n",
            "It: 520, Loss: 1.003e-01\n",
            "It: 530, Loss: 1.000e-01\n",
            "It: 540, Loss: 9.977e-02\n",
            "It: 550, Loss: 9.952e-02\n",
            "It: 560, Loss: 1.009e-01\n",
            "It: 570, Loss: 9.997e-02\n",
            "It: 580, Loss: 1.000e-01\n",
            "It: 590, Loss: 9.880e-02\n",
            "It: 600, Loss: 9.834e-02\n",
            "It: 610, Loss: 9.802e-02\n",
            "It: 620, Loss: 9.771e-02\n",
            "It: 630, Loss: 9.737e-02\n",
            "It: 640, Loss: 9.993e-02\n",
            "It: 650, Loss: 9.725e-02\n",
            "It: 660, Loss: 9.833e-02\n",
            "It: 670, Loss: 9.644e-02\n",
            "It: 680, Loss: 9.601e-02\n",
            "It: 690, Loss: 9.557e-02\n",
            "It: 700, Loss: 9.516e-02\n",
            "It: 710, Loss: 1.038e-01\n",
            "It: 720, Loss: 9.692e-02\n",
            "It: 730, Loss: 9.566e-02\n",
            "It: 740, Loss: 9.437e-02\n",
            "It: 750, Loss: 9.319e-02\n",
            "It: 760, Loss: 9.304e-02\n",
            "It: 770, Loss: 1.046e-01\n",
            "It: 780, Loss: 9.598e-02\n",
            "It: 790, Loss: 9.293e-02\n",
            "It: 800, Loss: 9.165e-02\n",
            "It: 810, Loss: 9.054e-02\n",
            "It: 820, Loss: 9.225e-02\n",
            "It: 830, Loss: 9.675e-02\n",
            "It: 840, Loss: 9.144e-02\n",
            "It: 850, Loss: 8.919e-02\n",
            "It: 860, Loss: 8.837e-02\n",
            "It: 870, Loss: 8.761e-02\n",
            "It: 880, Loss: 8.932e-02\n",
            "It: 890, Loss: 1.011e-01\n",
            "It: 900, Loss: 9.300e-02\n",
            "It: 910, Loss: 8.927e-02\n",
            "It: 920, Loss: 8.680e-02\n",
            "It: 930, Loss: 8.592e-02\n",
            "It: 940, Loss: 8.526e-02\n",
            "It: 950, Loss: 8.471e-02\n",
            "It: 960, Loss: 8.423e-02\n",
            "It: 970, Loss: 8.375e-02\n",
            "It: 980, Loss: 8.328e-02\n",
            "It: 990, Loss: 8.329e-02\n",
            "It: 1000, Loss: 9.004e-02\n",
            "It: 1010, Loss: 8.386e-02\n",
            "It: 1020, Loss: 8.408e-02\n",
            "It: 1030, Loss: 8.146e-02\n",
            "It: 1040, Loss: 8.086e-02\n",
            "It: 1050, Loss: 8.034e-02\n",
            "It: 1060, Loss: 7.979e-02\n",
            "It: 1070, Loss: 7.922e-02\n",
            "It: 1080, Loss: 7.916e-02\n",
            "It: 1090, Loss: 8.966e-02\n",
            "It: 1100, Loss: 7.914e-02\n",
            "It: 1110, Loss: 8.025e-02\n",
            "It: 1120, Loss: 7.716e-02\n",
            "It: 1130, Loss: 7.669e-02\n",
            "It: 1140, Loss: 7.621e-02\n",
            "It: 1150, Loss: 7.562e-02\n",
            "It: 1160, Loss: 7.532e-02\n",
            "It: 1170, Loss: 7.975e-02\n",
            "It: 1180, Loss: 7.716e-02\n",
            "It: 1190, Loss: 7.443e-02\n",
            "It: 1200, Loss: 7.432e-02\n",
            "It: 1210, Loss: 7.350e-02\n",
            "It: 1220, Loss: 7.296e-02\n",
            "It: 1230, Loss: 7.251e-02\n",
            "It: 1240, Loss: 9.327e-02\n",
            "It: 1250, Loss: 8.158e-02\n",
            "It: 1260, Loss: 7.322e-02\n",
            "It: 1270, Loss: 7.257e-02\n",
            "It: 1280, Loss: 7.118e-02\n",
            "It: 1290, Loss: 7.079e-02\n",
            "It: 1300, Loss: 7.027e-02\n",
            "It: 1310, Loss: 6.996e-02\n",
            "It: 1320, Loss: 8.115e-02\n",
            "It: 1330, Loss: 7.247e-02\n",
            "It: 1340, Loss: 7.159e-02\n",
            "It: 1350, Loss: 6.949e-02\n",
            "It: 1360, Loss: 6.896e-02\n",
            "It: 1370, Loss: 7.752e-02\n",
            "It: 1380, Loss: 6.801e-02\n",
            "It: 1390, Loss: 6.913e-02\n",
            "It: 1400, Loss: 6.645e-02\n",
            "It: 1410, Loss: 8.446e-02\n",
            "It: 1420, Loss: 6.574e-02\n",
            "It: 1430, Loss: 6.794e-02\n",
            "It: 1440, Loss: 6.782e-02\n",
            "It: 1450, Loss: 6.443e-02\n",
            "It: 1460, Loss: 6.366e-02\n",
            "It: 1470, Loss: 9.873e-02\n",
            "It: 1480, Loss: 8.664e-02\n",
            "It: 1490, Loss: 6.717e-02\n",
            "It: 1500, Loss: 6.763e-02\n",
            "It: 1510, Loss: 6.528e-02\n",
            "It: 1520, Loss: 6.260e-02\n",
            "It: 1530, Loss: 6.224e-02\n",
            "It: 1540, Loss: 6.154e-02\n",
            "It: 1550, Loss: 6.116e-02\n",
            "It: 1560, Loss: 6.083e-02\n",
            "It: 1570, Loss: 6.055e-02\n",
            "It: 1580, Loss: 6.030e-02\n",
            "It: 1590, Loss: 6.025e-02\n",
            "It: 1600, Loss: 8.110e-02\n",
            "It: 1610, Loss: 6.584e-02\n",
            "It: 1620, Loss: 6.186e-02\n",
            "It: 1630, Loss: 5.950e-02\n",
            "It: 1640, Loss: 5.968e-02\n",
            "It: 1650, Loss: 5.931e-02\n",
            "It: 1660, Loss: 5.891e-02\n",
            "It: 1670, Loss: 5.878e-02\n",
            "It: 1680, Loss: 6.394e-02\n",
            "It: 1690, Loss: 6.471e-02\n",
            "It: 1700, Loss: 5.865e-02\n",
            "It: 1710, Loss: 5.889e-02\n",
            "It: 1720, Loss: 5.837e-02\n",
            "It: 1730, Loss: 5.792e-02\n",
            "It: 1740, Loss: 5.791e-02\n",
            "It: 1750, Loss: 6.717e-02\n",
            "It: 1760, Loss: 6.284e-02\n",
            "It: 1770, Loss: 5.827e-02\n",
            "It: 1780, Loss: 5.766e-02\n",
            "It: 1790, Loss: 5.810e-02\n",
            "It: 1800, Loss: 5.748e-02\n",
            "It: 1810, Loss: 6.037e-02\n",
            "It: 1820, Loss: 5.681e-02\n",
            "It: 1830, Loss: 5.681e-02\n",
            "It: 1840, Loss: 5.928e-02\n",
            "It: 1850, Loss: 6.192e-02\n",
            "It: 1860, Loss: 5.737e-02\n",
            "It: 1870, Loss: 5.641e-02\n",
            "It: 1880, Loss: 5.698e-02\n",
            "It: 1890, Loss: 6.528e-02\n",
            "It: 1900, Loss: 5.985e-02\n",
            "It: 1910, Loss: 5.808e-02\n",
            "It: 1920, Loss: 5.620e-02\n",
            "It: 1930, Loss: 5.782e-02\n",
            "It: 1940, Loss: 5.597e-02\n",
            "It: 1950, Loss: 5.540e-02\n",
            "It: 1960, Loss: 5.732e-02\n",
            "It: 1970, Loss: 6.130e-02\n",
            "It: 1980, Loss: 5.673e-02\n",
            "It: 1990, Loss: 5.503e-02\n",
            "It: 2000, Loss: 5.662e-02\n",
            "It: 2010, Loss: 5.711e-02\n",
            "It: 2020, Loss: 5.482e-02\n",
            "It: 2030, Loss: 5.462e-02\n",
            "It: 2040, Loss: 5.451e-02\n",
            "It: 2050, Loss: 6.567e-02\n",
            "It: 2060, Loss: 5.585e-02\n",
            "It: 2070, Loss: 6.147e-02\n",
            "It: 2080, Loss: 5.501e-02\n",
            "It: 2090, Loss: 5.441e-02\n",
            "It: 2100, Loss: 5.430e-02\n",
            "It: 2110, Loss: 5.417e-02\n",
            "It: 2120, Loss: 5.395e-02\n",
            "It: 2130, Loss: 5.384e-02\n",
            "It: 2140, Loss: 5.375e-02\n",
            "It: 2150, Loss: 5.379e-02\n",
            "It: 2160, Loss: 7.285e-02\n",
            "It: 2170, Loss: 5.858e-02\n",
            "It: 2180, Loss: 5.366e-02\n",
            "It: 2190, Loss: 5.417e-02\n",
            "It: 2200, Loss: 5.357e-02\n",
            "It: 2210, Loss: 5.336e-02\n",
            "It: 2220, Loss: 5.428e-02\n",
            "It: 2230, Loss: 5.803e-02\n",
            "It: 2240, Loss: 5.330e-02\n",
            "It: 2250, Loss: 5.400e-02\n",
            "It: 2260, Loss: 5.312e-02\n",
            "It: 2270, Loss: 5.352e-02\n",
            "It: 2280, Loss: 5.312e-02\n",
            "It: 2290, Loss: 5.551e-02\n",
            "It: 2300, Loss: 5.291e-02\n",
            "It: 2310, Loss: 5.295e-02\n",
            "It: 2320, Loss: 5.428e-02\n",
            "It: 2330, Loss: 5.261e-02\n",
            "It: 2340, Loss: 5.593e-02\n",
            "It: 2350, Loss: 5.241e-02\n",
            "It: 2360, Loss: 5.247e-02\n",
            "It: 2370, Loss: 5.408e-02\n",
            "It: 2380, Loss: 5.233e-02\n",
            "It: 2390, Loss: 5.794e-02\n",
            "It: 2400, Loss: 5.547e-02\n",
            "It: 2410, Loss: 5.242e-02\n",
            "It: 2420, Loss: 5.322e-02\n",
            "It: 2430, Loss: 6.097e-02\n",
            "It: 2440, Loss: 5.510e-02\n",
            "It: 2450, Loss: 5.367e-02\n",
            "It: 2460, Loss: 5.303e-02\n",
            "It: 2470, Loss: 5.211e-02\n",
            "It: 2480, Loss: 5.171e-02\n",
            "It: 2490, Loss: 5.499e-02\n",
            "It: 2500, Loss: 5.348e-02\n",
            "It: 2510, Loss: 5.440e-02\n",
            "It: 2520, Loss: 5.187e-02\n",
            "It: 2530, Loss: 5.167e-02\n",
            "It: 2540, Loss: 5.208e-02\n",
            "It: 2550, Loss: 5.393e-02\n",
            "It: 2560, Loss: 5.284e-02\n",
            "It: 2570, Loss: 5.136e-02\n",
            "It: 2580, Loss: 5.233e-02\n",
            "It: 2590, Loss: 5.601e-02\n",
            "It: 2600, Loss: 5.154e-02\n",
            "It: 2610, Loss: 5.250e-02\n",
            "It: 2620, Loss: 5.178e-02\n",
            "It: 2630, Loss: 5.128e-02\n",
            "It: 2640, Loss: 5.116e-02\n",
            "It: 2650, Loss: 6.086e-02\n",
            "It: 2660, Loss: 5.338e-02\n",
            "It: 2670, Loss: 5.137e-02\n",
            "It: 2680, Loss: 5.136e-02\n",
            "It: 2690, Loss: 5.102e-02\n",
            "It: 2700, Loss: 5.377e-02\n",
            "It: 2710, Loss: 5.053e-02\n",
            "It: 2720, Loss: 5.194e-02\n",
            "It: 2730, Loss: 5.052e-02\n",
            "It: 2740, Loss: 5.727e-02\n",
            "It: 2750, Loss: 5.257e-02\n",
            "It: 2760, Loss: 5.166e-02\n",
            "It: 2770, Loss: 5.018e-02\n",
            "It: 2780, Loss: 5.144e-02\n",
            "It: 2790, Loss: 5.227e-02\n",
            "It: 2800, Loss: 5.165e-02\n",
            "It: 2810, Loss: 5.164e-02\n",
            "It: 2820, Loss: 5.138e-02\n",
            "It: 2830, Loss: 5.204e-02\n",
            "It: 2840, Loss: 5.018e-02\n",
            "It: 2850, Loss: 4.988e-02\n",
            "It: 2860, Loss: 5.471e-02\n",
            "It: 2870, Loss: 5.324e-02\n",
            "It: 2880, Loss: 5.177e-02\n",
            "It: 2890, Loss: 5.023e-02\n",
            "It: 2900, Loss: 4.990e-02\n",
            "It: 2910, Loss: 4.940e-02\n",
            "It: 2920, Loss: 5.031e-02\n",
            "It: 2930, Loss: 5.481e-02\n",
            "It: 2940, Loss: 5.081e-02\n",
            "It: 2950, Loss: 4.909e-02\n",
            "It: 2960, Loss: 5.113e-02\n",
            "It: 2970, Loss: 5.136e-02\n",
            "It: 2980, Loss: 5.006e-02\n",
            "It: 2990, Loss: 5.057e-02\n",
            "It: 3000, Loss: 5.051e-02\n",
            "It: 3010, Loss: 5.076e-02\n",
            "It: 3020, Loss: 5.047e-02\n",
            "It: 3030, Loss: 4.898e-02\n",
            "It: 3040, Loss: 4.952e-02\n",
            "It: 3050, Loss: 5.952e-02\n",
            "It: 3060, Loss: 4.980e-02\n",
            "It: 3070, Loss: 4.849e-02\n",
            "It: 3080, Loss: 4.866e-02\n",
            "It: 3090, Loss: 4.907e-02\n",
            "It: 3100, Loss: 5.157e-02\n",
            "It: 3110, Loss: 4.818e-02\n",
            "It: 3120, Loss: 5.074e-02\n",
            "It: 3130, Loss: 4.914e-02\n",
            "It: 3140, Loss: 5.017e-02\n",
            "It: 3150, Loss: 4.794e-02\n",
            "It: 3160, Loss: 5.092e-02\n",
            "It: 3170, Loss: 4.793e-02\n",
            "It: 3180, Loss: 4.920e-02\n",
            "It: 3190, Loss: 4.858e-02\n",
            "It: 3200, Loss: 4.785e-02\n",
            "It: 3210, Loss: 5.435e-02\n",
            "It: 3220, Loss: 5.159e-02\n",
            "It: 3230, Loss: 4.905e-02\n",
            "It: 3240, Loss: 4.783e-02\n",
            "It: 3250, Loss: 4.915e-02\n",
            "It: 3260, Loss: 4.911e-02\n",
            "It: 3270, Loss: 4.870e-02\n",
            "It: 3280, Loss: 4.898e-02\n",
            "It: 3290, Loss: 4.758e-02\n",
            "It: 3300, Loss: 4.807e-02\n",
            "It: 3310, Loss: 4.718e-02\n",
            "It: 3320, Loss: 4.761e-02\n",
            "It: 3330, Loss: 5.839e-02\n",
            "It: 3340, Loss: 4.722e-02\n",
            "It: 3350, Loss: 4.817e-02\n",
            "It: 3360, Loss: 4.748e-02\n",
            "It: 3370, Loss: 4.664e-02\n",
            "It: 3380, Loss: 4.710e-02\n",
            "It: 3390, Loss: 4.998e-02\n",
            "It: 3400, Loss: 4.662e-02\n",
            "It: 3410, Loss: 4.835e-02\n",
            "It: 3420, Loss: 4.680e-02\n",
            "It: 3430, Loss: 4.767e-02\n",
            "It: 3440, Loss: 5.076e-02\n",
            "It: 3450, Loss: 4.684e-02\n",
            "It: 3460, Loss: 4.628e-02\n",
            "It: 3470, Loss: 4.690e-02\n",
            "It: 3480, Loss: 5.020e-02\n",
            "It: 3490, Loss: 5.172e-02\n",
            "It: 3500, Loss: 4.686e-02\n",
            "It: 3510, Loss: 4.632e-02\n",
            "It: 3520, Loss: 4.607e-02\n",
            "It: 3530, Loss: 4.650e-02\n",
            "It: 3540, Loss: 4.914e-02\n",
            "It: 3550, Loss: 4.544e-02\n",
            "It: 3560, Loss: 4.803e-02\n",
            "It: 3570, Loss: 4.693e-02\n",
            "It: 3580, Loss: 4.561e-02\n",
            "It: 3590, Loss: 5.197e-02\n",
            "It: 3600, Loss: 4.769e-02\n",
            "It: 3610, Loss: 4.640e-02\n",
            "It: 3620, Loss: 4.496e-02\n",
            "It: 3630, Loss: 4.690e-02\n",
            "It: 3640, Loss: 4.734e-02\n",
            "It: 3650, Loss: 4.683e-02\n",
            "It: 3660, Loss: 4.473e-02\n",
            "It: 3670, Loss: 4.464e-02\n",
            "It: 3680, Loss: 5.821e-02\n",
            "It: 3690, Loss: 4.474e-02\n",
            "It: 3700, Loss: 4.453e-02\n",
            "It: 3710, Loss: 4.460e-02\n",
            "It: 3720, Loss: 5.624e-02\n",
            "It: 3730, Loss: 4.949e-02\n",
            "It: 3740, Loss: 4.496e-02\n",
            "It: 3750, Loss: 4.499e-02\n",
            "It: 3760, Loss: 4.411e-02\n",
            "It: 3770, Loss: 4.684e-02\n",
            "It: 3780, Loss: 4.451e-02\n",
            "It: 3790, Loss: 4.511e-02\n",
            "It: 3800, Loss: 4.517e-02\n",
            "It: 3810, Loss: 4.774e-02\n",
            "It: 3820, Loss: 4.514e-02\n",
            "It: 3830, Loss: 4.370e-02\n",
            "It: 3840, Loss: 4.331e-02\n",
            "It: 3850, Loss: 4.327e-02\n",
            "It: 3860, Loss: 6.548e-02\n",
            "It: 3870, Loss: 4.408e-02\n",
            "It: 3880, Loss: 4.521e-02\n",
            "It: 3890, Loss: 4.317e-02\n",
            "It: 3900, Loss: 4.385e-02\n",
            "It: 3910, Loss: 4.292e-02\n",
            "It: 3920, Loss: 4.281e-02\n",
            "It: 3930, Loss: 4.275e-02\n",
            "It: 3940, Loss: 4.261e-02\n",
            "It: 3950, Loss: 4.266e-02\n",
            "It: 3960, Loss: 4.795e-02\n",
            "It: 3970, Loss: 4.615e-02\n",
            "It: 3980, Loss: 4.322e-02\n",
            "It: 3990, Loss: 4.255e-02\n",
            "It: 4000, Loss: 4.247e-02\n",
            "It: 4010, Loss: 4.296e-02\n",
            "It: 4020, Loss: 5.634e-02\n",
            "It: 4030, Loss: 4.311e-02\n",
            "It: 4040, Loss: 4.437e-02\n",
            "It: 4050, Loss: 4.271e-02\n",
            "It: 4060, Loss: 4.228e-02\n",
            "It: 4070, Loss: 4.183e-02\n",
            "It: 4080, Loss: 4.288e-02\n",
            "It: 4090, Loss: 4.676e-02\n",
            "It: 4100, Loss: 4.346e-02\n",
            "It: 4110, Loss: 4.139e-02\n",
            "It: 4120, Loss: 4.268e-02\n",
            "It: 4130, Loss: 4.699e-02\n",
            "It: 4140, Loss: 4.300e-02\n",
            "It: 4150, Loss: 4.314e-02\n",
            "It: 4160, Loss: 4.247e-02\n",
            "It: 4170, Loss: 4.421e-02\n",
            "It: 4180, Loss: 4.106e-02\n",
            "It: 4190, Loss: 4.120e-02\n",
            "It: 4200, Loss: 4.337e-02\n",
            "It: 4210, Loss: 4.084e-02\n",
            "It: 4220, Loss: 4.129e-02\n",
            "It: 4230, Loss: 5.078e-02\n",
            "It: 4240, Loss: 4.438e-02\n",
            "It: 4250, Loss: 4.171e-02\n",
            "It: 4260, Loss: 4.156e-02\n",
            "It: 4270, Loss: 4.035e-02\n",
            "It: 4280, Loss: 4.254e-02\n",
            "It: 4290, Loss: 4.234e-02\n",
            "It: 4300, Loss: 4.106e-02\n",
            "It: 4310, Loss: 4.144e-02\n",
            "It: 4320, Loss: 4.156e-02\n",
            "It: 4330, Loss: 4.042e-02\n",
            "It: 4340, Loss: 4.031e-02\n",
            "It: 4350, Loss: 5.084e-02\n",
            "It: 4360, Loss: 4.437e-02\n",
            "It: 4370, Loss: 4.149e-02\n",
            "It: 4380, Loss: 4.003e-02\n",
            "It: 4390, Loss: 3.957e-02\n",
            "It: 4400, Loss: 3.969e-02\n",
            "It: 4410, Loss: 4.424e-02\n",
            "It: 4420, Loss: 4.112e-02\n",
            "It: 4430, Loss: 4.063e-02\n",
            "It: 4440, Loss: 4.023e-02\n",
            "It: 4450, Loss: 4.062e-02\n",
            "It: 4460, Loss: 4.142e-02\n",
            "It: 4470, Loss: 3.971e-02\n",
            "It: 4480, Loss: 3.901e-02\n",
            "It: 4490, Loss: 4.209e-02\n",
            "It: 4500, Loss: 3.936e-02\n",
            "It: 4510, Loss: 4.280e-02\n",
            "It: 4520, Loss: 3.960e-02\n",
            "It: 4530, Loss: 3.895e-02\n",
            "It: 4540, Loss: 3.898e-02\n",
            "It: 4550, Loss: 4.219e-02\n",
            "It: 4560, Loss: 4.430e-02\n",
            "It: 4570, Loss: 3.955e-02\n",
            "It: 4580, Loss: 3.840e-02\n",
            "It: 4590, Loss: 3.823e-02\n",
            "It: 4600, Loss: 3.821e-02\n",
            "It: 4610, Loss: 4.119e-02\n",
            "It: 4620, Loss: 3.834e-02\n",
            "It: 4630, Loss: 4.099e-02\n",
            "It: 4640, Loss: 3.932e-02\n",
            "It: 4650, Loss: 3.846e-02\n",
            "It: 4660, Loss: 3.800e-02\n",
            "It: 4670, Loss: 3.817e-02\n",
            "It: 4680, Loss: 3.940e-02\n",
            "It: 4690, Loss: 4.121e-02\n",
            "It: 4700, Loss: 3.927e-02\n",
            "It: 4710, Loss: 3.781e-02\n",
            "It: 4720, Loss: 3.868e-02\n",
            "It: 4730, Loss: 3.847e-02\n",
            "It: 4740, Loss: 3.926e-02\n",
            "It: 4750, Loss: 4.000e-02\n",
            "It: 4760, Loss: 3.803e-02\n",
            "It: 4770, Loss: 3.912e-02\n",
            "It: 4780, Loss: 3.848e-02\n",
            "It: 4790, Loss: 3.742e-02\n",
            "It: 4800, Loss: 3.900e-02\n",
            "It: 4810, Loss: 4.034e-02\n",
            "It: 4820, Loss: 3.812e-02\n",
            "It: 4830, Loss: 3.760e-02\n",
            "It: 4840, Loss: 3.768e-02\n",
            "It: 4850, Loss: 3.769e-02\n",
            "It: 4860, Loss: 4.791e-02\n",
            "It: 4870, Loss: 3.839e-02\n",
            "It: 4880, Loss: 3.786e-02\n",
            "It: 4890, Loss: 3.704e-02\n",
            "It: 4900, Loss: 3.675e-02\n",
            "It: 4910, Loss: 3.893e-02\n",
            "It: 4920, Loss: 3.768e-02\n",
            "It: 4930, Loss: 3.716e-02\n",
            "It: 4940, Loss: 3.749e-02\n",
            "It: 4950, Loss: 3.741e-02\n",
            "It: 4960, Loss: 3.643e-02\n",
            "It: 4970, Loss: 3.950e-02\n",
            "It: 4980, Loss: 3.730e-02\n",
            "It: 4990, Loss: 3.840e-02\n",
            "It: 5000, Loss: 3.830e-02\n",
            "It: 5010, Loss: 3.814e-02\n",
            "It: 5020, Loss: 3.649e-02\n",
            "It: 5030, Loss: 3.692e-02\n",
            "It: 5040, Loss: 3.879e-02\n",
            "It: 5050, Loss: 3.678e-02\n",
            "It: 5060, Loss: 3.668e-02\n",
            "It: 5070, Loss: 3.778e-02\n",
            "It: 5080, Loss: 4.018e-02\n",
            "It: 5090, Loss: 3.761e-02\n",
            "It: 5100, Loss: 3.602e-02\n",
            "It: 5110, Loss: 3.720e-02\n",
            "It: 5120, Loss: 3.828e-02\n",
            "It: 5130, Loss: 3.714e-02\n",
            "It: 5140, Loss: 3.630e-02\n",
            "It: 5150, Loss: 3.698e-02\n",
            "It: 5160, Loss: 3.562e-02\n",
            "It: 5170, Loss: 3.849e-02\n",
            "It: 5180, Loss: 3.820e-02\n",
            "It: 5190, Loss: 3.700e-02\n",
            "It: 5200, Loss: 3.494e-02\n",
            "It: 5210, Loss: 3.614e-02\n",
            "It: 5220, Loss: 3.844e-02\n",
            "It: 5230, Loss: 3.615e-02\n",
            "It: 5240, Loss: 3.579e-02\n",
            "It: 5250, Loss: 3.597e-02\n",
            "It: 5260, Loss: 3.574e-02\n",
            "It: 5270, Loss: 3.663e-02\n",
            "It: 5280, Loss: 3.514e-02\n",
            "It: 5290, Loss: 3.458e-02\n",
            "It: 5300, Loss: 3.559e-02\n",
            "It: 5310, Loss: 4.351e-02\n",
            "It: 5320, Loss: 3.591e-02\n",
            "It: 5330, Loss: 3.469e-02\n",
            "It: 5340, Loss: 3.450e-02\n",
            "It: 5350, Loss: 3.420e-02\n",
            "It: 5360, Loss: 3.451e-02\n",
            "It: 5370, Loss: 4.455e-02\n",
            "It: 5380, Loss: 3.865e-02\n",
            "It: 5390, Loss: 3.456e-02\n",
            "It: 5400, Loss: 3.479e-02\n",
            "It: 5410, Loss: 3.406e-02\n",
            "It: 5420, Loss: 3.417e-02\n",
            "It: 5430, Loss: 4.986e-02\n",
            "It: 5440, Loss: 3.781e-02\n",
            "It: 5450, Loss: 3.613e-02\n",
            "It: 5460, Loss: 3.370e-02\n",
            "It: 5470, Loss: 3.377e-02\n",
            "It: 5480, Loss: 3.364e-02\n",
            "It: 5490, Loss: 3.354e-02\n",
            "It: 5500, Loss: 4.227e-02\n",
            "It: 5510, Loss: 3.797e-02\n",
            "It: 5520, Loss: 3.466e-02\n",
            "It: 5530, Loss: 3.432e-02\n",
            "It: 5540, Loss: 3.337e-02\n",
            "It: 5550, Loss: 3.359e-02\n",
            "It: 5560, Loss: 3.648e-02\n",
            "It: 5570, Loss: 3.379e-02\n",
            "It: 5580, Loss: 3.457e-02\n",
            "It: 5590, Loss: 3.458e-02\n",
            "It: 5600, Loss: 3.367e-02\n",
            "It: 5610, Loss: 3.869e-02\n",
            "It: 5620, Loss: 3.386e-02\n",
            "It: 5630, Loss: 3.294e-02\n",
            "It: 5640, Loss: 3.542e-02\n",
            "It: 5650, Loss: 3.479e-02\n",
            "It: 5660, Loss: 3.348e-02\n",
            "It: 5670, Loss: 3.364e-02\n",
            "It: 5680, Loss: 3.480e-02\n",
            "It: 5690, Loss: 3.302e-02\n",
            "It: 5700, Loss: 3.435e-02\n",
            "It: 5710, Loss: 3.372e-02\n",
            "It: 5720, Loss: 3.297e-02\n",
            "It: 5730, Loss: 3.642e-02\n",
            "It: 5740, Loss: 3.308e-02\n",
            "It: 5750, Loss: 3.329e-02\n",
            "It: 5760, Loss: 3.275e-02\n",
            "It: 5770, Loss: 3.230e-02\n",
            "It: 5780, Loss: 3.291e-02\n",
            "It: 5790, Loss: 3.837e-02\n",
            "It: 5800, Loss: 3.554e-02\n",
            "It: 5810, Loss: 3.529e-02\n",
            "It: 5820, Loss: 3.364e-02\n",
            "It: 5830, Loss: 3.263e-02\n",
            "It: 5840, Loss: 3.189e-02\n",
            "It: 5850, Loss: 3.582e-02\n",
            "It: 5860, Loss: 3.831e-02\n",
            "It: 5870, Loss: 3.343e-02\n",
            "It: 5880, Loss: 3.286e-02\n",
            "It: 5890, Loss: 3.190e-02\n",
            "It: 5900, Loss: 3.270e-02\n",
            "It: 5910, Loss: 3.907e-02\n",
            "It: 5920, Loss: 3.278e-02\n",
            "It: 5930, Loss: 3.168e-02\n",
            "It: 5940, Loss: 3.166e-02\n",
            "It: 5950, Loss: 3.169e-02\n",
            "It: 5960, Loss: 3.177e-02\n",
            "It: 5970, Loss: 3.459e-02\n",
            "It: 5980, Loss: 3.179e-02\n",
            "It: 5990, Loss: 3.329e-02\n",
            "It: 6000, Loss: 3.451e-02\n",
            "It: 6010, Loss: 3.256e-02\n",
            "It: 6020, Loss: 3.200e-02\n",
            "It: 6030, Loss: 3.232e-02\n",
            "It: 6040, Loss: 3.976e-02\n",
            "It: 6050, Loss: 3.214e-02\n",
            "It: 6060, Loss: 3.129e-02\n",
            "It: 6070, Loss: 3.138e-02\n",
            "It: 6080, Loss: 3.100e-02\n",
            "It: 6090, Loss: 3.602e-02\n",
            "It: 6100, Loss: 3.864e-02\n",
            "It: 6110, Loss: 3.286e-02\n",
            "It: 6120, Loss: 3.101e-02\n",
            "It: 6130, Loss: 3.111e-02\n",
            "It: 6140, Loss: 3.086e-02\n",
            "It: 6150, Loss: 3.086e-02\n",
            "It: 6160, Loss: 3.609e-02\n",
            "It: 6170, Loss: 3.726e-02\n",
            "It: 6180, Loss: 3.348e-02\n",
            "It: 6190, Loss: 3.109e-02\n",
            "It: 6200, Loss: 3.136e-02\n",
            "It: 6210, Loss: 3.090e-02\n",
            "It: 6220, Loss: 3.057e-02\n",
            "It: 6230, Loss: 3.221e-02\n",
            "It: 6240, Loss: 3.131e-02\n",
            "It: 6250, Loss: 3.358e-02\n",
            "It: 6260, Loss: 3.097e-02\n",
            "It: 6270, Loss: 3.080e-02\n",
            "It: 6280, Loss: 3.053e-02\n",
            "It: 6290, Loss: 3.248e-02\n",
            "It: 6300, Loss: 3.094e-02\n",
            "It: 6310, Loss: 3.655e-02\n",
            "It: 6320, Loss: 3.048e-02\n",
            "It: 6330, Loss: 3.110e-02\n",
            "It: 6340, Loss: 3.052e-02\n",
            "It: 6350, Loss: 3.037e-02\n",
            "It: 6360, Loss: 3.025e-02\n",
            "It: 6370, Loss: 3.342e-02\n",
            "It: 6380, Loss: 3.102e-02\n",
            "It: 6390, Loss: 3.202e-02\n",
            "It: 6400, Loss: 3.112e-02\n",
            "It: 6410, Loss: 3.205e-02\n",
            "It: 6420, Loss: 3.335e-02\n",
            "It: 6430, Loss: 3.071e-02\n",
            "It: 6440, Loss: 3.026e-02\n",
            "It: 6450, Loss: 3.049e-02\n",
            "It: 6460, Loss: 3.042e-02\n",
            "It: 6470, Loss: 3.090e-02\n",
            "It: 6480, Loss: 3.364e-02\n",
            "It: 6490, Loss: 3.024e-02\n",
            "It: 6500, Loss: 3.035e-02\n",
            "It: 6510, Loss: 3.059e-02\n",
            "It: 6520, Loss: 3.873e-02\n",
            "It: 6530, Loss: 3.359e-02\n",
            "It: 6540, Loss: 3.288e-02\n",
            "It: 6550, Loss: 3.119e-02\n",
            "It: 6560, Loss: 3.003e-02\n",
            "It: 6570, Loss: 2.991e-02\n",
            "It: 6580, Loss: 3.593e-02\n",
            "It: 6590, Loss: 3.542e-02\n",
            "It: 6600, Loss: 3.082e-02\n",
            "It: 6610, Loss: 2.995e-02\n",
            "It: 6620, Loss: 3.016e-02\n",
            "It: 6630, Loss: 3.872e-02\n",
            "It: 6640, Loss: 3.496e-02\n",
            "It: 6650, Loss: 3.231e-02\n",
            "It: 6660, Loss: 3.063e-02\n",
            "It: 6670, Loss: 3.001e-02\n",
            "It: 6680, Loss: 2.939e-02\n",
            "It: 6690, Loss: 3.009e-02\n",
            "It: 6700, Loss: 3.772e-02\n",
            "It: 6710, Loss: 3.067e-02\n",
            "It: 6720, Loss: 3.126e-02\n",
            "It: 6730, Loss: 2.998e-02\n",
            "It: 6740, Loss: 3.009e-02\n",
            "It: 6750, Loss: 3.514e-02\n",
            "It: 6760, Loss: 3.041e-02\n",
            "It: 6770, Loss: 3.004e-02\n",
            "It: 6780, Loss: 2.989e-02\n",
            "It: 6790, Loss: 3.338e-02\n",
            "It: 6800, Loss: 2.930e-02\n",
            "It: 6810, Loss: 3.193e-02\n",
            "It: 6820, Loss: 2.959e-02\n",
            "It: 6830, Loss: 3.356e-02\n",
            "It: 6840, Loss: 3.442e-02\n",
            "It: 6850, Loss: 3.092e-02\n",
            "It: 6860, Loss: 3.051e-02\n",
            "It: 6870, Loss: 3.098e-02\n",
            "It: 6880, Loss: 3.071e-02\n",
            "It: 6890, Loss: 2.996e-02\n",
            "It: 6900, Loss: 3.055e-02\n",
            "It: 6910, Loss: 3.228e-02\n",
            "It: 6920, Loss: 3.058e-02\n",
            "It: 6930, Loss: 3.062e-02\n",
            "It: 6940, Loss: 3.011e-02\n",
            "It: 6950, Loss: 2.986e-02\n",
            "It: 6960, Loss: 3.435e-02\n",
            "It: 6970, Loss: 2.931e-02\n",
            "It: 6980, Loss: 2.988e-02\n",
            "It: 6990, Loss: 2.969e-02\n",
            "It: 7000, Loss: 3.118e-02\n",
            "It: 7010, Loss: 2.954e-02\n",
            "It: 7020, Loss: 3.175e-02\n",
            "It: 7030, Loss: 3.167e-02\n",
            "It: 7040, Loss: 2.918e-02\n",
            "It: 7050, Loss: 2.961e-02\n",
            "It: 7060, Loss: 2.957e-02\n",
            "It: 7070, Loss: 3.747e-02\n",
            "It: 7080, Loss: 3.036e-02\n",
            "It: 7090, Loss: 2.873e-02\n",
            "It: 7100, Loss: 2.884e-02\n",
            "It: 7110, Loss: 2.880e-02\n",
            "It: 7120, Loss: 3.460e-02\n",
            "It: 7130, Loss: 3.215e-02\n",
            "It: 7140, Loss: 3.084e-02\n",
            "It: 7150, Loss: 2.861e-02\n",
            "It: 7160, Loss: 2.871e-02\n",
            "It: 7170, Loss: 2.874e-02\n",
            "It: 7180, Loss: 3.412e-02\n",
            "It: 7190, Loss: 3.119e-02\n",
            "It: 7200, Loss: 3.009e-02\n",
            "It: 7210, Loss: 2.897e-02\n",
            "It: 7220, Loss: 2.872e-02\n",
            "It: 7230, Loss: 2.875e-02\n",
            "It: 7240, Loss: 3.301e-02\n",
            "It: 7250, Loss: 3.111e-02\n",
            "It: 7260, Loss: 3.277e-02\n",
            "It: 7270, Loss: 2.872e-02\n",
            "It: 7280, Loss: 2.881e-02\n",
            "It: 7290, Loss: 2.870e-02\n",
            "It: 7300, Loss: 3.695e-02\n",
            "It: 7310, Loss: 3.475e-02\n",
            "It: 7320, Loss: 2.994e-02\n",
            "It: 7330, Loss: 2.880e-02\n",
            "It: 7340, Loss: 2.872e-02\n",
            "It: 7350, Loss: 2.845e-02\n",
            "It: 7360, Loss: 2.850e-02\n",
            "It: 7370, Loss: 3.223e-02\n",
            "It: 7380, Loss: 2.840e-02\n",
            "It: 7390, Loss: 2.865e-02\n",
            "It: 7400, Loss: 2.850e-02\n",
            "It: 7410, Loss: 2.823e-02\n",
            "It: 7420, Loss: 2.861e-02\n",
            "It: 7430, Loss: 2.863e-02\n",
            "It: 7440, Loss: 3.815e-02\n",
            "It: 7450, Loss: 3.365e-02\n",
            "It: 7460, Loss: 3.018e-02\n",
            "It: 7470, Loss: 2.873e-02\n",
            "It: 7480, Loss: 2.817e-02\n",
            "It: 7490, Loss: 2.824e-02\n",
            "It: 7500, Loss: 2.843e-02\n",
            "It: 7510, Loss: 4.835e-02\n",
            "It: 7520, Loss: 2.984e-02\n",
            "It: 7530, Loss: 3.108e-02\n",
            "It: 7540, Loss: 2.837e-02\n",
            "It: 7550, Loss: 2.823e-02\n",
            "It: 7560, Loss: 2.820e-02\n",
            "It: 7570, Loss: 2.805e-02\n",
            "It: 7580, Loss: 2.809e-02\n",
            "It: 7590, Loss: 3.213e-02\n",
            "It: 7600, Loss: 3.537e-02\n",
            "It: 7610, Loss: 2.928e-02\n",
            "It: 7620, Loss: 2.875e-02\n",
            "It: 7630, Loss: 2.831e-02\n",
            "It: 7640, Loss: 2.811e-02\n",
            "It: 7650, Loss: 2.797e-02\n",
            "It: 7660, Loss: 2.842e-02\n",
            "It: 7670, Loss: 4.147e-02\n",
            "It: 7680, Loss: 3.084e-02\n",
            "It: 7690, Loss: 2.872e-02\n",
            "It: 7700, Loss: 2.900e-02\n",
            "It: 7710, Loss: 2.828e-02\n",
            "It: 7720, Loss: 2.808e-02\n",
            "It: 7730, Loss: 2.804e-02\n",
            "It: 7740, Loss: 3.192e-02\n",
            "It: 7750, Loss: 2.948e-02\n",
            "It: 7760, Loss: 2.993e-02\n",
            "It: 7770, Loss: 2.842e-02\n",
            "It: 7780, Loss: 2.818e-02\n",
            "It: 7790, Loss: 2.957e-02\n",
            "It: 7800, Loss: 3.167e-02\n",
            "It: 7810, Loss: 2.958e-02\n",
            "It: 7820, Loss: 2.869e-02\n",
            "It: 7830, Loss: 2.838e-02\n",
            "It: 7840, Loss: 2.914e-02\n",
            "It: 7850, Loss: 3.363e-02\n",
            "It: 7860, Loss: 3.038e-02\n",
            "It: 7870, Loss: 2.905e-02\n",
            "It: 7880, Loss: 2.843e-02\n",
            "It: 7890, Loss: 2.814e-02\n",
            "It: 7900, Loss: 3.472e-02\n",
            "It: 7910, Loss: 2.976e-02\n",
            "It: 7920, Loss: 2.900e-02\n",
            "It: 7930, Loss: 2.829e-02\n",
            "It: 7940, Loss: 2.830e-02\n",
            "It: 7950, Loss: 3.580e-02\n",
            "It: 7960, Loss: 2.896e-02\n",
            "It: 7970, Loss: 2.778e-02\n",
            "It: 7980, Loss: 2.811e-02\n",
            "It: 7990, Loss: 2.796e-02\n",
            "It: 8000, Loss: 3.062e-02\n",
            "It: 8010, Loss: 2.842e-02\n",
            "It: 8020, Loss: 2.764e-02\n",
            "It: 8030, Loss: 2.764e-02\n",
            "It: 8040, Loss: 2.781e-02\n",
            "It: 8050, Loss: 2.829e-02\n",
            "It: 8060, Loss: 3.901e-02\n",
            "It: 8070, Loss: 2.825e-02\n",
            "It: 8080, Loss: 2.894e-02\n",
            "It: 8090, Loss: 2.789e-02\n",
            "It: 8100, Loss: 2.787e-02\n",
            "It: 8110, Loss: 2.771e-02\n",
            "It: 8120, Loss: 2.901e-02\n",
            "It: 8130, Loss: 3.137e-02\n",
            "It: 8140, Loss: 2.815e-02\n",
            "It: 8150, Loss: 2.960e-02\n",
            "It: 8160, Loss: 2.842e-02\n",
            "It: 8170, Loss: 2.782e-02\n",
            "It: 8180, Loss: 2.768e-02\n",
            "It: 8190, Loss: 2.753e-02\n",
            "It: 8200, Loss: 2.895e-02\n",
            "It: 8210, Loss: 2.812e-02\n",
            "It: 8220, Loss: 3.065e-02\n",
            "It: 8230, Loss: 2.769e-02\n",
            "It: 8240, Loss: 2.799e-02\n",
            "It: 8250, Loss: 2.808e-02\n",
            "It: 8260, Loss: 3.747e-02\n",
            "It: 8270, Loss: 3.266e-02\n",
            "It: 8280, Loss: 2.916e-02\n",
            "It: 8290, Loss: 2.813e-02\n",
            "It: 8300, Loss: 2.795e-02\n",
            "It: 8310, Loss: 2.838e-02\n",
            "It: 8320, Loss: 3.203e-02\n",
            "It: 8330, Loss: 2.901e-02\n",
            "It: 8340, Loss: 2.820e-02\n",
            "It: 8350, Loss: 2.769e-02\n",
            "It: 8360, Loss: 2.738e-02\n",
            "It: 8370, Loss: 2.747e-02\n",
            "It: 8380, Loss: 3.425e-02\n",
            "It: 8390, Loss: 3.431e-02\n",
            "It: 8400, Loss: 2.957e-02\n",
            "It: 8410, Loss: 2.820e-02\n",
            "It: 8420, Loss: 2.805e-02\n",
            "It: 8430, Loss: 2.748e-02\n",
            "It: 8440, Loss: 2.740e-02\n",
            "It: 8450, Loss: 2.741e-02\n",
            "It: 8460, Loss: 3.357e-02\n",
            "It: 8470, Loss: 3.223e-02\n",
            "It: 8480, Loss: 2.759e-02\n",
            "It: 8490, Loss: 2.803e-02\n",
            "It: 8500, Loss: 2.731e-02\n",
            "It: 8510, Loss: 2.727e-02\n",
            "It: 8520, Loss: 2.777e-02\n",
            "It: 8530, Loss: 3.924e-02\n",
            "It: 8540, Loss: 2.985e-02\n",
            "It: 8550, Loss: 2.748e-02\n",
            "It: 8560, Loss: 2.803e-02\n",
            "It: 8570, Loss: 2.761e-02\n",
            "It: 8580, Loss: 2.727e-02\n",
            "It: 8590, Loss: 2.733e-02\n",
            "It: 8600, Loss: 3.187e-02\n",
            "It: 8610, Loss: 3.434e-02\n",
            "It: 8620, Loss: 2.799e-02\n",
            "It: 8630, Loss: 2.735e-02\n",
            "It: 8640, Loss: 2.774e-02\n",
            "It: 8650, Loss: 2.720e-02\n",
            "It: 8660, Loss: 2.725e-02\n",
            "It: 8670, Loss: 2.752e-02\n",
            "It: 8680, Loss: 4.431e-02\n",
            "It: 8690, Loss: 3.075e-02\n",
            "It: 8700, Loss: 2.804e-02\n",
            "It: 8710, Loss: 2.848e-02\n",
            "It: 8720, Loss: 2.738e-02\n",
            "It: 8730, Loss: 2.721e-02\n",
            "It: 8740, Loss: 2.717e-02\n",
            "It: 8750, Loss: 2.732e-02\n",
            "It: 8760, Loss: 3.376e-02\n",
            "It: 8770, Loss: 2.952e-02\n",
            "It: 8780, Loss: 2.718e-02\n",
            "It: 8790, Loss: 3.093e-02\n",
            "It: 8800, Loss: 2.979e-02\n",
            "It: 8810, Loss: 2.947e-02\n",
            "It: 8820, Loss: 2.770e-02\n",
            "It: 8830, Loss: 2.733e-02\n",
            "It: 8840, Loss: 2.928e-02\n",
            "It: 8850, Loss: 2.864e-02\n",
            "It: 8860, Loss: 2.865e-02\n",
            "It: 8870, Loss: 2.757e-02\n",
            "It: 8880, Loss: 2.774e-02\n",
            "It: 8890, Loss: 2.742e-02\n",
            "It: 8900, Loss: 3.160e-02\n",
            "It: 8910, Loss: 2.724e-02\n",
            "It: 8920, Loss: 2.710e-02\n",
            "It: 8930, Loss: 2.777e-02\n",
            "It: 8940, Loss: 2.737e-02\n",
            "It: 8950, Loss: 3.670e-02\n",
            "It: 8960, Loss: 3.047e-02\n",
            "It: 8970, Loss: 2.753e-02\n",
            "It: 8980, Loss: 2.777e-02\n",
            "It: 8990, Loss: 2.720e-02\n",
            "It: 9000, Loss: 2.813e-02\n",
            "It: 9010, Loss: 3.275e-02\n",
            "It: 9020, Loss: 2.849e-02\n",
            "It: 9030, Loss: 2.777e-02\n",
            "It: 9040, Loss: 2.748e-02\n",
            "It: 9050, Loss: 2.716e-02\n",
            "It: 9060, Loss: 2.822e-02\n",
            "It: 9070, Loss: 3.157e-02\n",
            "It: 9080, Loss: 2.764e-02\n",
            "It: 9090, Loss: 2.725e-02\n",
            "It: 9100, Loss: 2.713e-02\n",
            "It: 9110, Loss: 2.771e-02\n",
            "It: 9120, Loss: 3.540e-02\n",
            "It: 9130, Loss: 3.033e-02\n",
            "It: 9140, Loss: 2.862e-02\n",
            "It: 9150, Loss: 2.739e-02\n",
            "It: 9160, Loss: 2.697e-02\n",
            "It: 9170, Loss: 2.762e-02\n",
            "It: 9180, Loss: 3.142e-02\n",
            "It: 9190, Loss: 2.827e-02\n",
            "It: 9200, Loss: 2.803e-02\n",
            "It: 9210, Loss: 2.975e-02\n",
            "It: 9220, Loss: 2.696e-02\n",
            "It: 9230, Loss: 2.828e-02\n",
            "It: 9240, Loss: 2.822e-02\n",
            "It: 9250, Loss: 2.773e-02\n",
            "It: 9260, Loss: 3.526e-02\n",
            "It: 9270, Loss: 2.834e-02\n",
            "It: 9280, Loss: 2.694e-02\n",
            "It: 9290, Loss: 2.707e-02\n",
            "It: 9300, Loss: 2.690e-02\n",
            "It: 9310, Loss: 2.820e-02\n",
            "It: 9320, Loss: 3.002e-02\n",
            "It: 9330, Loss: 2.779e-02\n",
            "It: 9340, Loss: 2.865e-02\n",
            "It: 9350, Loss: 2.721e-02\n",
            "It: 9360, Loss: 2.689e-02\n",
            "It: 9370, Loss: 2.689e-02\n",
            "It: 9380, Loss: 2.674e-02\n",
            "It: 9390, Loss: 2.745e-02\n",
            "It: 9400, Loss: 3.386e-02\n",
            "It: 9410, Loss: 2.997e-02\n",
            "It: 9420, Loss: 2.690e-02\n",
            "It: 9430, Loss: 2.740e-02\n",
            "It: 9440, Loss: 2.686e-02\n",
            "It: 9450, Loss: 2.683e-02\n",
            "It: 9460, Loss: 2.676e-02\n",
            "It: 9470, Loss: 2.928e-02\n",
            "It: 9480, Loss: 3.016e-02\n",
            "It: 9490, Loss: 2.998e-02\n",
            "It: 9500, Loss: 2.802e-02\n",
            "It: 9510, Loss: 2.715e-02\n",
            "It: 9520, Loss: 2.670e-02\n",
            "It: 9530, Loss: 2.681e-02\n",
            "It: 9540, Loss: 3.288e-02\n",
            "It: 9550, Loss: 2.975e-02\n",
            "It: 9560, Loss: 3.009e-02\n",
            "It: 9570, Loss: 2.737e-02\n",
            "It: 9580, Loss: 2.677e-02\n",
            "It: 9590, Loss: 2.677e-02\n",
            "It: 9600, Loss: 2.677e-02\n",
            "It: 9610, Loss: 2.681e-02\n",
            "It: 9620, Loss: 2.867e-02\n",
            "It: 9630, Loss: 2.874e-02\n",
            "It: 9640, Loss: 2.882e-02\n",
            "It: 9650, Loss: 2.731e-02\n",
            "It: 9660, Loss: 2.675e-02\n",
            "It: 9670, Loss: 2.665e-02\n",
            "It: 9680, Loss: 2.665e-02\n",
            "It: 9690, Loss: 2.918e-02\n",
            "It: 9700, Loss: 2.891e-02\n",
            "It: 9710, Loss: 3.001e-02\n",
            "It: 9720, Loss: 2.882e-02\n",
            "It: 9730, Loss: 2.666e-02\n",
            "It: 9740, Loss: 2.695e-02\n",
            "It: 9750, Loss: 2.666e-02\n",
            "It: 9760, Loss: 2.657e-02\n",
            "It: 9770, Loss: 2.657e-02\n",
            "It: 9780, Loss: 2.656e-02\n",
            "It: 9790, Loss: 3.055e-02\n",
            "It: 9800, Loss: 3.556e-02\n",
            "It: 9810, Loss: 3.043e-02\n",
            "It: 9820, Loss: 2.827e-02\n",
            "It: 9830, Loss: 2.712e-02\n",
            "It: 9840, Loss: 2.661e-02\n",
            "It: 9850, Loss: 2.658e-02\n",
            "It: 9860, Loss: 2.653e-02\n",
            "It: 9870, Loss: 2.652e-02\n",
            "It: 9880, Loss: 2.672e-02\n",
            "It: 9890, Loss: 4.839e-02\n",
            "It: 9900, Loss: 2.748e-02\n",
            "It: 9910, Loss: 2.958e-02\n",
            "It: 9920, Loss: 2.753e-02\n",
            "It: 9930, Loss: 2.658e-02\n",
            "It: 9940, Loss: 2.664e-02\n",
            "It: 9950, Loss: 2.655e-02\n",
            "It: 9960, Loss: 2.649e-02\n",
            "It: 9970, Loss: 2.654e-02\n",
            "It: 9980, Loss: 3.603e-02\n",
            "It: 9990, Loss: 3.496e-02\n",
            "--- 3300.6259458065033 seconds ---\n",
            "Save uv NN parameters successfully...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "        # Get mixed-form PINN prediction\n",
        "        x_PINN = np.linspace(0, 1.2, 251)\n",
        "        y_PINN = np.linspace(0, 0.40, 101)\n",
        "        x_PINN, y_PINN = np.meshgrid(x_PINN, y_PINN)\n",
        "        x_PINN = x_PINN.flatten()[:, None]\n",
        "        y_PINN = y_PINN.flatten()[:, None]\n",
        "        dst = ((x_PINN-0.2)**2+(y_PINN-0.2)**2)**0.5\n",
        "        x_PINN = x_PINN[dst >= 0.05]\n",
        "        y_PINN = y_PINN[dst >= 0.05]\n",
        "        x_PINN = x_PINN.flatten()[:, None]\n",
        "        y_PINN = y_PINN.flatten()[:, None]\n",
        "        c_PINN = np.zeros(49154)[:, None]\n",
        "        index_1m_0_6m = np.where((x_PINN == 1.0) & (y_PINN == 0.6))[0]\n",
        "        c_PINN[1:100] = 100\n",
        "        u_PINN, v_PINN, p_PINN, c_star = model.predict(x_PINN, y_PINN)\n",
        "        field_MIXED = [x_PINN, y_PINN, u_PINN, v_PINN, p_PINN, c_PINN]\n",
        "\n",
        "        # Plot the comparison of u, v, p, c\n",
        "        postProcess(xmin=0, xmax=1.2, ymin=0, ymax=0.40, field_MIXED=field_MIXED, s=3, alpha=0.5)"
      ],
      "metadata": {
        "id": "9MDW0s2_pHho"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}