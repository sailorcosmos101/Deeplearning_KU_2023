{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0SzzUz6CGpQhg2uMkpCBR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sailorcosmos101/Deeplearning_KU_2023/blob/main/PINN_laminar_flow_1115.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bnTsDh-qSHFl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import scipy.io\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "AI5KNcQ9Tcf3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PINN_laminar_flow:\n",
        "  def __init__(self,Collo,INLET,OUTLET,WALL,uv_layers,lb,ub,ExistModel=0,uvDir=''):\n",
        "    # Count for callback function\n",
        "    self.count=0\n",
        "\n",
        "    # Bounds\n",
        "    self.lb=lb\n",
        "    self.ub=ub\n",
        "\n",
        "    # Mat. properties\n",
        "    self.rho=1.0\n",
        "    self.mu=0.02\n",
        "\n",
        "    # Collocation point\n",
        "    self.x_c=Collo[:,0:1]\n",
        "    self.y_c=Collo[:,1:2]\n",
        "\n",
        "    self.x_INLET=INLET[:,0:1]\n",
        "    self.y_INLET=INLET[:,1:2]\n",
        "    self.u_INLET=INLET[:,2:3]\n",
        "    self.v_INLET=INLET[:,3:4]\n",
        "\n",
        "    self.x_OUTLET=OUTLET[:,0:1]\n",
        "    self.y_OUTLET=OUTLET[:,1:2]\n",
        "\n",
        "    self.x_WALL=WALL[:,0:1]\n",
        "    self.y_WALL=WALL[:,1:2]\n",
        "\n",
        "    self.uv_layers=uv_layers\n",
        "    self.loss_rec=[]\n",
        "\n",
        "    # Initialize NNs\n",
        "    self.uv_weights, self.uv_biases = self.initialize_NN(self.uv_layers)\n",
        "\n",
        "    # tf placeholders\n",
        "    self.learning_rate = tf.placeholder(tf.float32, shape=[])\n",
        "    self.x_tf = tf.placeholder(tf.float, shape=[None,self.x_c.shape[1]])\n",
        "    self.y_tf = tf.placeholder(tf.float, shape=[None,self.y_c.shape[1]])\n",
        "    self.x_WALL_tf = tf.placeholder(tf.float, shape=[None,self.x_WALL.shape[1]])\n",
        "    self.y_WALL_tf = tf.placeholder(tf.float, shape=[None,self.y_WALL.shape[1]])\n",
        "    self.x_INLET_tf = tf.placeholder(tf.float, shape=[None,self.x_INLET.shape[1]])\n",
        "    self.y_INLET_tf = tf.placeholder(tf.float, shape=[None,self.y_INLET.shape[1]])\n",
        "    self.u_INLET_tf = tf.placeholder(tf.float, shape=[None,self.u_INLET.shape[1]])\n",
        "    self.v_INLET_tf = tf.placeholder(tf.float, shape=[None,self.v_INLET.shape[1]])\n",
        "    self.x_OUTLET_tf = tf.placeholder(tf.float, shape=[None,self.x_OUTLET.shape[1]])\n",
        "    self.y_OUTLET_tf = tf.placeholder(tf.float, shape=[None,self.y_OUTLET.shape[1]])\n",
        "    self.x_c_tf = tf.placeholder(tf.float, shape=[None,self.x_c.shape[1]])\n",
        "    self.y_c_tf = tf.placeholder(tf.float, shape=[None,self.y_c.shape[1]])\n",
        "\n",
        "    # tf graphs\n",
        "    self.u_pred, self.v_pred, self.p_pred, _, _, _ = self.net_uv(self.x_Tf, self.y_tf)\n",
        "    self.f_pred_u, self.f_pred_v, self.f_pred_s11, self.f_pred_s22, self.f_pred_s12, self.f_pred_p = self.net_f(self.x_c_tf, self.y_c_tf)\n",
        "    self.u_WALL_pred, self.v_WALL_pred, _, _, _, _ = self.net_uv(self.x_WALL_tf, self.y_WALL_tf)\n",
        "    self.u_INLET_pred, self.v_INLET_pred, _, _, _, _ = self.net_uv(self.x_INLET_tf, self.y_INLET_tf)\n",
        "    _, _, self.p_OUTLET_pred, _, _, _ = self.net_uv(self.x_OUTLET_tf, self.y_OUTLET_tf)\n",
        "\n",
        "    self.loss_f = tf.reduce_mean(tf.square(self.f_pred_u)) + tf.reduce_mean(tf.square(self.f_pred_v)) + tf.reduce_mean(tf.square(self.f_pred_s11)) + tf.reduce_mean(tf.square(self.f_pred_s22)) + tf.reduce_mean(tf.square(self.f_pred_s12)) + tf.reduce_mean(tf.square(self.f_pred_p))\n",
        "    self.loss_WALL = tf.reduce_mean(tf.square(self.u_WALL_pred)) + tf.reduce_mean(tf.square(self.v_WALL_pred))\n",
        "    self.loss_INLET = tf.reduce_mean(tf.square(self.u_INLET_pred-self.u_INLET_Tf)) + tf.reduce_mean(tf.square(self.v_INLET_pred-self.v_INLET_tf))\n",
        "    self.loss_OUTLET = tf.reduce_mean(tf.square(self.p_OUTLET_pred))\n",
        "    self.loss = self.loss_f + 2*(self.loss_WALL + self.loss_INLET + self.loss_OUTLET)\n",
        "\n",
        "    # Optimizer for solution\n",
        "    self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss,\n",
        "                                                                var_list=self.uv_weights + self.uv_biases,\n",
        "                                                                method='L-BFGS-B',\n",
        "                                                                options={'maxiter': 100000,\n",
        "                                                                         'maxfun': 100000,\n",
        "                                                                         'maxcor': 50,\n",
        "                                                                         'maxls': 50,\n",
        "                                                                         'ftol': 1*np.finfo(float).eps})\n",
        "    self.optimizer_Adam = tf.train.AdamOptimizer(learning_rate = self.learning_rate)\n",
        "    self.train_op_Adam = self.optimizer_Adam.minimize(self.loss,var_list=self.uv_weights + self.uv_biases)\n",
        "\n",
        "    # tf session\n",
        "    self.sees = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True))\n",
        "    init=tf.global_variables_initializer()\n",
        "    self.sees.run(init)\n",
        "\n",
        "  def initialize_NN(self,layers):\n",
        "    weights = []\n",
        "    biases = []\n",
        "    num_layers = len(layers)\n",
        "    for l in range(0,num_layers - 1):\n",
        "      W = self.xavier_init(size=[layers[l], layers[l+1]])\n",
        "      b= = tf.Variable(tf.zeros([1, layers[1+l]], dtype=tf.float32), dtype=tf.float32)\n",
        "      weights.append(W)\n",
        "      biases.append(b)\n",
        "    return weights, biases\n",
        "\n",
        "  def xavier_init(self, size):\n",
        "    in_dim = size[0]\n",
        "    out_dim = size[1]\n",
        "    xavier_staddev = np.sqrt(2 / (in_dim + out_dim))\n",
        "    return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev, dtype=tf.float32), dtype=tf.float32)\n",
        "\n",
        "  def save_NN(self, fileDir):\n",
        "\n",
        "  def load_NN(self, fileDir, layers):\n",
        "\n",
        "  def neural_net(self,X,weights,biases):\n",
        "      num_layers = len(weights)+1\n",
        "      H = X\n",
        "\n",
        "      for l in range(0, num_layers - 2):\n",
        "        W = weights[l]\n",
        "        b = biases[l]\n",
        "        H = tf.tanh(tf.add(tf.matmul(H,W),b))\n",
        "      W = weights[-1]\n",
        "      b = biases[-1]\n",
        "      Y = tf.add(tf.matul(H, W),b)\n",
        "      return Y\n",
        "\n",
        "  def net_uv(self, x, y):\n",
        "    psips = self.neural_net(tf.concat([x, y],1), self.uv_weights, self.uv_biases)\n",
        "    psi = psips[:,0:1]\n",
        "    p = psips[:,1:2]\n",
        "    s11 = psips[:, 2:3]\n",
        "    s22 = psips[:, 3:4]\n",
        "    s12 = psips[:, 4:5]\n",
        "    u = tf.gradients(psi, y)[0]\n",
        "    v = -tf.gradients(psi, x)[0]\n",
        "    return u, v, p, s11, s22, s12\n",
        "\n",
        "  def net_f(self, x, y):\n",
        "    rho = self.rho\n",
        "    mu = self.mu\n",
        "    u, v, p, s11, s22, s12 = self.net_uv(x,y)\n",
        "\n",
        "    s11_1\n",
        "    s12_2\n",
        "    s22_2\n",
        "    s12_1\n",
        "\n",
        "    u_x\n",
        "    u_y\n",
        "\n",
        "\n",
        "  def callback(self,loss):\n",
        "    self.count = self.count+1\n",
        "    self.loss_rec.append(loss)\n",
        "    print('{}th iterations, Loss: {}'.format(self.count,loss))\n",
        "\n",
        "  def train(self, iter, learning_rate):\n",
        "    tf_dict = {self.x_c_tf: self.x_c,\n",
        "               self.y_c_tf: self.y_c,\n",
        "               self.x_WALL_tf: self.x_WALL,\n",
        "               self.y_WALL_tf: self.y_WALL,\n",
        "               self.x_INLET_tf: self}\n",
        "    loss_WALL = []\n",
        "    loss_f = []\n",
        "    loss_INLET = []\n",
        "    loss_OUTLET = []\n",
        "\n",
        "    for it in range(iter):\n",
        "      self.sess.run()\n",
        "\n",
        "  # bfgs???\n",
        "  def train_bfgs(self):\n",
        "\n",
        "\n",
        "  def predict(self,x_star,y_star):\n",
        "\n",
        "  # Loss function\n",
        "  def getloss(self):\n",
        "\n",
        "    tf_dict\n",
        "\n",
        "    loss_f = self.sess.run\n",
        "    loss_uv = self.sess.run\n",
        "\n"
      ],
      "metadata": {
        "id": "Jll_N1iwoz9i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "4c8230d4-dc45-4633-bb86-b95d4f374203"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-ec11f9ca1082>\"\u001b[0;36m, line \u001b[0;32m55\u001b[0m\n\u001b[0;31m    def load_NN(self, fileDir, layers):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Preprocess(dir=):\n",
        "  X = data['x']\n",
        "  Y = data['y']\n",
        "\n",
        "  x_star = X.flatten()[:,None]\n",
        "  y_star = Y.flatten()[:,None]\n",
        "\n",
        "  return x_star, y_star"
      ],
      "metadata": {
        "id": "WsczC6o9F0c-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Postprocess():\n"
      ],
      "metadata": {
        "id": "KmBhM0UzNCnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__==\"__main__\":\n",
        "  # Domain bounds\n",
        "  lb =\n",
        "  up =\n",
        "\n",
        "  # Network configuration\n",
        "\n",
        "  # Wall = [x,y]\n",
        "  wall_up =\n",
        "  wall_lw =\n",
        "\n",
        "  # INLET = [x,y]\n",
        "  U_max =\n",
        "\n",
        "  # Collocation point for equation residual\n",
        "\n",
        "  # Visualize the collocation points\n",
        "\n",
        "  # Train from scratch\n",
        "\n",
        "  # Load trained neural network\n",
        "\n",
        "  # Save neural network\n",
        "\n",
        "  # Save loss history\n",
        "\n",
        "  # Load fluent result\n",
        "\n",
        "  # Get mixed-form PINN prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "M3WZnnyfOF-U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}